# ðŸš€ Patch "Torre (Qwen2.5-7B)" â€“ ConfiguraÃ§Ã£o no Cursor

Este patch permite usar a **Torre LLM** diretamente no Cursor via LM Studio ou Ollama.

---

## ðŸ“‹ OpÃ§Ã£o 1: **LM Studio** (Recomendado)

### 1. **Configure o LM Studio**
- Abra **LM Studio** â†’ **Developer â†’ Local Server â†’ Start**
- Anote o endereÃ§o: normalmente `http://localhost:1234/v1`
- [DocumentaÃ§Ã£o LM Studio](https://lmstudio.ai/docs/api/openai-api)

### 2. **Configure o Cursor**
No **Cursor â†’ Settings â†’ Models â†’ API Keys**:

* **Override Base URL (OpenAI-compatible):**
  ```
  http://localhost:1234/v1
  ```

* **API Key:**
  ```
  local
  ```

* Clique **Verify/Save**

### 3. **Adicione o Modelo**
Ainda em **Models**, clique **Add model** e preencha:

* **Display name:**
  ```
  Torre
  ```

* **Model (ID):**
  ```
  qwen2.5-7b-instruct
  ```

* Salve

---

## ðŸ“‹ OpÃ§Ã£o 2: **Ollama** (Alternativo)

### 1. **Configure o Ollama**
- Garanta o Ollama aberto
- Ele expÃµe API OpenAI-compatÃ­vel em `http://localhost:11434/v1`
- [GitHub Ollama](https://github.com/cursor/cursor/issues/1380)

### 2. **Configure o Cursor**
No **Cursor â†’ Settings â†’ Models â†’ API Keys**:

* **Override Base URL:**
  ```
  http://localhost:11434/v1
  ```

* **API Key:**
  ```
  local
  ```

* **Save/Verify**

### 3. **Adicione o Modelo**
**Models â†’ Add model**:

* **Display name:**
  ```
  Torre
  ```

* **Model (ID):**
  ```
  qwen2.5:7b-instruct
  ```

* Salve

---

## ðŸ§ª **Teste no Chat do Cursor**

```
[Modelo: Torre]
Diga "OlÃ¡! Sou a Torre (Qwen2.5-7B)".
```

---

## ðŸ’¡ **Dicas Importantes**

* O **nome tem que bater** com o ID que o servidor mostra (Ã© sensÃ­vel a maiÃºsculas/minÃºsculas e espaÃ§os)
* Recursos especiais do Cursor (ex.: *tab completion*) podem continuar usando modelos internos; isso Ã© normal
* Se o LM Studio mostrar um ID ligeiramente diferente, copie exatamente o que aparecer lÃ¡

---

## ðŸ”— **Links Ãšteis**

- [DocumentaÃ§Ã£o Cursor - API Keys](https://docs.cursor.com/settings/api-keys)
- [Cursor Community Forum - Local LLMs](https://forum.cursor.com/t/using-local-llms-with-cursor-is-it-possible/15494)
- [LM Studio - OpenAI Compatibility API](https://lmstudio.ai/docs/api/openai-api)
- [Ollama GitHub Issue](https://github.com/cursor/cursor/issues/1380)

---

## ðŸŽ¯ **Resultado**

ApÃ³s a configuraÃ§Ã£o, vocÃª terÃ¡ acesso Ã  **Torre LLM** diretamente no Cursor, permitindo:

- âœ… Chat com a Torre
- âœ… CorreÃ§Ã£o de cÃ³digo
- âœ… SugestÃµes inteligentes
- âœ… IntegraÃ§Ã£o completa com o ecossistema Torre

**A Torre estÃ¡ pronta para ser sua assistente de programaÃ§Ã£o!** ðŸš€
