diff --git a/llm/cli.py b/llm/cli.py
index 1234567..abcdefg 100644
--- a/llm/cli.py
+++ b/llm/cli.py
@@ -15,6 +15,7 @@ import subprocess
 import tempfile
 import json
 import os
+from pathlib import Path
 
 # ... existing imports ...
 
@@ -45,6 +46,25 @@ def run_llm_fix(
     max_retries: int = 3,
     **kwargs
 ) -> Dict[str, Any]:
+    """
+    Executa pipeline de correÃ§Ã£o automÃ¡tica antes do LLM.
+    """
+    
+    # 1. Executar fixers determinÃ­sticos prÃ©-LLM
+    print("ðŸ”§ Executando pipeline de correÃ§Ã£o automÃ¡tica...")
+    try:
+        result = subprocess.run(
+            ["make", "pre-llm"], 
+            capture_output=True, 
+            text=True, 
+            cwd=Path(__file__).parent.parent,
+            timeout=300
+        )
+        if result.returncode == 0:
+            print("âœ… CorreÃ§Ã£o automÃ¡tica aplicada com sucesso")
+        else:
+            print(f"âš ï¸  CorreÃ§Ã£o automÃ¡tica falhou: {result.stderr}")
+    except Exception as e:
+        print(f"âš ï¸  Erro na correÃ§Ã£o automÃ¡tica: {e}")
 
     # ... existing LLM fix logic ...
 
@@ -120,6 +140,25 @@ def run_llm_fix(
         # ... existing error handling ...
         
         # 2. Se falhou, tentar APR baseado em padrÃµes
+        print("ðŸ” Tentando APR baseado em padrÃµes...")
+        try:
+            apr_result = subprocess.run(
+                ["make", "apr"],
+                capture_output=True,
+                text=True,
+                cwd=Path(__file__).parent.parent,
+                timeout=600
+            )
+            if apr_result.returncode == 0:
+                apr_data = json.loads(apr_result.stdout)
+                if apr_data.get("validation", {}).get("ok"):
+                    print("âœ… APR aplicado com sucesso")
+                    return {"success": True, "method": "apr", "data": apr_data}
+                else:
+                    print(f"âš ï¸  APR falhou na validaÃ§Ã£o: {apr_data}")
+        except Exception as e:
+            print(f"âš ï¸  Erro no APR: {e}")
 
         # ... continue with LLM ...
 
@@ -180,6 +219,15 @@ def run_llm_fix(
             # ... existing success handling ...
             
             # 3. Gravar episÃ³dio para mineraÃ§Ã£o futura
+            try:
+                episode = {
+                    "timestamp": datetime.now().isoformat(),
+                    "err_code": error_code,
+                    "diff": diff_output,
+                    "success": True,
+                    "method": "llm"
+                }
+                _save_episode(episode)
+            except Exception as e:
+                print(f"âš ï¸  Erro ao salvar episÃ³dio: {e}")
 
             return {"success": True, "diff": diff_output}
 
@@ -200,6 +248,25 @@ def run_llm_fix(
     return {"success": False, "error": "Max retries exceeded"}
 
 
+def _save_episode(episode: Dict[str, Any]) -> None:
+    """
+    Salva episÃ³dio para mineraÃ§Ã£o de padrÃµes.
+    """
+    episodes_file = Path(__file__).parent.parent / ".fortaleza" / "memory" / "episodes.jsonl"
+    episodes_file.parent.mkdir(parents=True, exist_ok=True)
+    
+    with open(episodes_file, "a") as f:
+        f.write(json.dumps(episode) + "\n")


+def run_fixer_pipeline() -> Dict[str, Any]:
+    """
+    Executa pipeline completa de correÃ§Ã£o (1â†’11).
+    """
+    result = subprocess.run(["make", "fix-all"], capture_output=True, text=True)
+    return {"success": result.returncode == 0, "output": result.stdout, "error": result.stderr}
+
+
 # ... rest of existing code ...
