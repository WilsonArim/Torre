#!/usr/bin/env python3
"""
PIN ‚Äî GATEKEEPER v3.0
Guardi√£o √âtico e Fiscalizador Final

REGRA DE ABERTURA:
OWNER: GATEKEEPER ‚Äî Pr√≥xima a√ß√£o: <frase curta>

PAPEL: emitir pareceres, auditar gates, bloquear/liberar pipeline quando necess√°rio.

REGRAS:
- Avalia conformidade √©tica e t√©cnica ap√≥s valida√ß√£o SOP.
- N√£o planeia; apenas julga e reporta pareceres.
- Deve respeitar ART-01 (Integridade), ART-04 (Verificabilidade), ART-07 (Transpar√™ncia), ART-09 (Evid√™ncia)

SA√çDAS:
- relatorios/parecer_gatekeeper.md + relatorios/para_estado_maior/gatekeeper.out.json
"""
import argparse
import json
import os
import re
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence

try:
    import yaml  # type: ignore
except Exception:
    yaml = None

# Importar guardas de acesso a ficheiros
try:
    from file_access_guard import validar_permissao_escrita, validar_formato_relatorio, formatar_resposta_agente
except ImportError:
    # Fallback se n√£o conseguir importar
    def validar_permissao_escrita(agente: str, caminho: Path, tem_ordem_valida: bool = False):
        # Em modo fallback, validar conforme agente
        caminho_str = str(caminho)
        if agente == "GATEKEEPER":
            if caminho.suffix == ".md" or "relatorios/para_estado_maior/" in caminho_str:
                return True, "OK"
        return True, "OK (fallback)"  # Modo permissivo em fallback
    
    def validar_formato_relatorio(conteudo: str):
        return True, "OK (fallback)"
    
    def formatar_resposta_agente(agente: str, conteudo: str, pipeline_status: str = "FORA_PIPELINE", proxima_acao: str = "", comando_executar: str = ""):
        # Fallback: garantir formato m√≠nimo mesmo sem importa√ß√£o
        if not proxima_acao:
            proxima_acao = "Opera√ß√£o conclu√≠da"
        if not comando_executar:
            comando_executar = "ESTADO-MAIOR ANALISAR RESPOSTA E CONTINUAR OPERA√á√ÉO"
        
        return f"""**PIPELINE/FORA_PIPELINE:** {pipeline_status}

**OWNER: {agente} ‚Äî Pr√≥xima a√ß√£o:** {proxima_acao}

{conteudo}

---

**COMANDO A EXECUTAR:** "{comando_executar}"
"""


REPO_ROOT = Path(__file__).resolve().parents[2]
ORDERS_DIR = REPO_ROOT / "ordem" / "ordens"
REPORTS_DIR = REPO_ROOT / "relatorios" / "para_estado_maior"
GATEKEEPER_IN = ORDERS_DIR / "gatekeeper.in.yaml"
GATEKEEPER_OUT = REPORTS_DIR / "gatekeeper.out.json"
REL_DIR = REPO_ROOT / "relatorios"
PARECER_PATH = REL_DIR / "parecer_gatekeeper.md"
ORQUESTRADOR_DIR = REPO_ROOT / "core" / "orquestrador"
VALIDATOR_SCRIPT = REPO_ROOT / "core" / "scripts" / "validator.py"


def _run_bash_command(command: str | Sequence[str], timeout: int) -> subprocess.CompletedProcess[str]:
    """
    Executa comando sem usar shell=True (evita vulnerabilidades B602).
    Aceita string (executada via bash -lc) ou sequ√™ncia de argumentos.
    """
    if isinstance(command, (list, tuple)):
        cmd_list = [str(arg) for arg in command]
    else:
        cmd_list = ["bash", "-lc", command]

    return subprocess.run(
        cmd_list,
        cwd=str(REPO_ROOT),
        capture_output=True,
        text=True,
        timeout=timeout,
    )


def load_yaml(path: Path) -> Any:
    """Carrega ficheiro YAML (retorna lista ou dict conforme conte√∫do)."""
    if not path.exists():
        return []
    if yaml is None:
        return []
    try:
        content = path.read_text(encoding="utf-8")
        data = yaml.safe_load(content)
        if data is None:
            return []
        # Se for lista, filtrar None e garantir que s√£o dicts
        if isinstance(data, list):
            return [item for item in data if isinstance(item, dict)]
        return data
    except Exception:
        return []


def save_json(path: Path, data: List[Dict[str, Any]]) -> None:
    """Guarda lista de relat√≥rios em JSON."""
    # Validar permiss√£o de escrita conforme doutrina
    permite, mensagem = validar_permissao_escrita("GATEKEEPER", path, tem_ordem_valida=False)
    if not permite:
        raise PermissionError(f"‚ùå BLOQUEADO: {mensagem}")
    
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def load_json(path: Path) -> List[Dict[str, Any]]:
    """Carrega ficheiro JSON."""
    if not path.exists():
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data if isinstance(data, list) else [data]
    except Exception:
        return []


def write_text(path: Path, content: str) -> None:
    """Escreve texto em ficheiro com valida√ß√£o de permiss√£o e formato."""
    # Validar permiss√£o de escrita conforme doutrina
    permite, mensagem = validar_permissao_escrita("GATEKEEPER", path, tem_ordem_valida=False)
    if not permite:
        raise PermissionError(f"‚ùå BLOQUEADO: {mensagem}")
    
    # Validar formato se for markdown
    if path.suffix == ".md":
        formato_ok, formato_msg = validar_formato_relatorio(content)
        if not formato_ok:
            raise ValueError(f"‚ùå BLOQUEADO: {formato_msg}")
    
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def cmd_executa() -> int:
    """Executa ordem do Gatekeeper conforme mailbox."""
    print("=" * 50)
    print("üõ°Ô∏è GATEKEEPER v3.0 ‚Äî Execu√ß√£o de Ordem")
    print("=" * 50)
    
    # Carregar ordens
    orders = load_yaml(GATEKEEPER_IN)
    if not orders:
        conteudo = "‚ùå Nenhuma ordem encontrada em gatekeeper.in.yaml"
        resposta_formatada = formatar_resposta_agente(
            "GATEKEEPER",
            conteudo,
            pipeline_status="FORA_PIPELINE",
            proxima_acao="Aguardando ordem do Estado-Maior",
            comando_executar="ESTADO-MAIOR CRIAR ORDEM PARA GATEKEEPER EM ordem/ordens/gatekeeper.in.yaml"
        )
        print(resposta_formatada)
        return 1
    
    # Encontrar ordem aberta
    open_order = None
    for order in orders:
        if order.get("status") == "OPEN":
            open_order = order
            break
    
    if not open_order:
        conteudo = "‚ùå Nenhuma ordem aberta encontrada"
        resposta_formatada = formatar_resposta_agente(
            "GATEKEEPER",
            conteudo,
            pipeline_status="FORA_PIPELINE",
            proxima_acao="Aguardando ordem aberta do Estado-Maior",
            comando_executar="ESTADO-MAIOR CRIAR ORDEM ABERTA PARA GATEKEEPER"
        )
        print(resposta_formatada)
        return 1
    
    order_id = open_order.get("order_id", "unknown")
    objective = open_order.get("objective", "N/A")
    
    print(f"üìã Ordem encontrada: {order_id}")
    print(f"üéØ Objetivo: {objective}")
    
    # Preparar inputs do Gatekeeper (gatekeeper_prep)
    print("\nüì¶ Preparando inputs do Gatekeeper...")
    makefile_dir = ORQUESTRADOR_DIR.absolute()
    prep_cmd = f'make -C "{makefile_dir}" gatekeeper_prep'
    prep_result = _run_bash_command(
        prep_cmd,
        timeout=300,
    )
    
    if prep_result.returncode != 0:
        conteudo = f"‚ùå Erro ao preparar inputs do Gatekeeper:\n{prep_result.stderr[:500]}"
        resposta_formatada = formatar_resposta_agente(
            "GATEKEEPER",
            conteudo,
            pipeline_status="FORA_PIPELINE",
            proxima_acao="Corrigir prepara√ß√£o de inputs",
            comando_executar="ENGENHEIRO CORRIGIR PREPARA√á√ÉO DE INPUTS DO GATEKEEPER"
        )
        print(resposta_formatada)
        return 1
    
    # Verificar status SOP
    sop_status_path = REPORTS_DIR / "sop_status.json"
    sop_status = {}
    if sop_status_path.exists():
        try:
            sop_data = load_json(sop_status_path)
            if isinstance(sop_data, dict):
                sop_status = sop_data
            elif isinstance(sop_data, list) and sop_data:
                sop_status = sop_data[0]
        except Exception:
            pass
    
    # Verificar artefactos obrigat√≥rios
    artefactos_obrigatorios = [
        REL_DIR / "pipeline_gate_input.json",
        REL_DIR / "sbom.json",
        REL_DIR / "coverage.xml",
        REL_DIR / "parecer_gatekeeper.md",
    ]
    
    artefactos_presentes = []
    artefactos_faltando = []
    
    for artefacto in artefactos_obrigatorios:
        if artefacto.exists():
            artefactos_presentes.append(str(artefacto.relative_to(REPO_ROOT)))
        else:
            artefactos_faltando.append(str(artefacto.relative_to(REPO_ROOT)))
    
    # Determinar decis√£o
    sop_pass = sop_status.get("status") == "PASS"
    todos_artefactos = len(artefactos_faltando) == 0
    
    if sop_pass and todos_artefactos:
        decisao = "PASS"
        decisao_texto = "‚úÖ PASS"
    else:
        decisao = "BLOCKED"
        decisao_texto = "‚ùå BLOCKED"
    
    # Gerar parecer
    print("\nüìÑ Gerando parecer do Gatekeeper...")
    
    parecer_lines = [
        "# Parecer Gatekeeper ‚Äì Auditoria",
        "",
        f"**Data:** {datetime.now(timezone.utc).isoformat()}",
        f"**Ordem referenciada:** {order_id}",
        "",
        "## Decis√£o",
        "",
        decisao_texto,
        "",
    ]
    
    if decisao == "PASS":
        parecer_lines.append("Todos os artefactos obrigat√≥rios foram encontrados e validados:")
        for artefacto in artefactos_presentes:
            parecer_lines.append(f"- {artefacto}")
    else:
        parecer_lines.append("Bloqueio devido a:")
        if not sop_pass:
            parecer_lines.append("- Status SOP n√£o √© PASS")
        if artefactos_faltando:
            parecer_lines.append("- Artefactos faltando:")
            for artefacto in artefactos_faltando:
                parecer_lines.append(f"  - {artefacto}")
    
    parecer_lines.extend([
        "",
        "## Constraints analisados",
        f"- Status SOP: {'‚úîÔ∏è' if sop_pass else '‚ùå'}",
        f"- Artefactos obrigat√≥rios presentes: {'‚úîÔ∏è' if todos_artefactos else '‚ùå'}",
        "",
        "## Refer√™ncias constitucionais",
        "- ART-04: Verificabilidade",
        "- ART-07: Transpar√™ncia",
        "- ART-09: Evid√™ncia",
        "",
        f"**Assinado:** Gatekeeper (emiss√£o automatizada)",
    ])
    
    parecer_conteudo = "\n".join(parecer_lines)
    
    # Adicionar formato obrigat√≥rio ao parecer
    parecer_formatado = formatar_resposta_agente(
        "GATEKEEPER",
        parecer_conteudo,
        pipeline_status="PIPELINE" if decisao == "PASS" else "FORA_PIPELINE",
        proxima_acao=f"Parecer emitido: {decisao}",
        comando_executar="ESTADO-MAIOR ANALISAR PARECER DO GATEKEEPER E DECIDIR PR√ìXIMA A√á√ÉO"
    )
    
    # Salvar parecer
    write_text(PARECER_PATH, parecer_formatado)
    
    # Gerar relat√≥rio JSON
    report = {
        "order_id": order_id,
        "report_id": f"gk-{datetime.now(timezone.utc).isoformat()}",
        "version": 1,
        "from_role": "GATEKEEPER",
        "to_role": "ESTADO-MAIOR",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "decision": decisao,
        "sop_status": sop_status.get("status", "UNKNOWN"),
        "artefactos_presentes": artefactos_presentes,
        "artefactos_faltando": artefactos_faltando,
        "parecer_path": str(PARECER_PATH.relative_to(REPO_ROOT)),
    }
    
    reports = load_json(GATEKEEPER_OUT)
    reports.append(report)
    save_json(GATEKEEPER_OUT, reports)
    
    # Atualizar ordem para DONE
    open_order["status"] = "DONE"
    open_order["completed_at"] = datetime.now(timezone.utc).isoformat()
    orders_updated = []
    for o in orders:
        if o.get("order_id") == order_id:
            orders_updated.append(open_order)
        else:
            orders_updated.append(o)
    
    # Salvar ordens atualizadas
    if yaml:
        with open(GATEKEEPER_IN, "w", encoding="utf-8") as f:
            yaml.dump(orders_updated, f, allow_unicode=True, default_flow_style=False)
    
    # Formatar resposta final
    conteudo_resposta = f"""‚úÖ Parecer do Gatekeeper gerado

**Decis√£o:** {decisao_texto}

**Artefactos verificados:**
- Presentes: {len(artefactos_presentes)}/{len(artefactos_obrigatorios)}
- Faltando: {len(artefactos_faltando)}

**Status SOP:** {sop_status.get('status', 'UNKNOWN')}

**Parecer salvo em:** {PARECER_PATH.relative_to(REPO_ROOT)}
**Relat√≥rio salvo em:** {GATEKEEPER_OUT.relative_to(REPO_ROOT)}
"""
    
    resposta_formatada = formatar_resposta_agente(
        "GATEKEEPER",
        conteudo_resposta,
        pipeline_status="PIPELINE" if decisao == "PASS" else "FORA_PIPELINE",
        proxima_acao=f"Parecer emitido: {decisao}",
        comando_executar="ESTADO-MAIOR ANALISAR PARECER DO GATEKEEPER E DECIDIR PR√ìXIMA A√á√ÉO"
    )
    
    print(resposta_formatada)
    
    return 0 if decisao == "PASS" else 1


def cmd_status() -> int:
    """Mostra status atual do Gatekeeper."""
    conteudo_resposta = "üõ°Ô∏è GATEKEEPER v3.0 ‚Äî Status\n" + "=" * 50
    
    # Verificar ordens
    orders = load_yaml(GATEKEEPER_IN)
    open_orders = [o for o in orders if o.get("status") == "OPEN"]
    
    conteudo_resposta += f"\n\nüìã Ordens:\n   Abertas: {len(open_orders)}"
    
    # Verificar parecer mais recente
    if PARECER_PATH.exists():
        try:
            parecer_content = PARECER_PATH.read_text(encoding="utf-8")
            if "‚úÖ PASS" in parecer_content:
                conteudo_resposta += "\n\n‚úÖ √öltimo parecer: PASS"
            elif "‚ùå BLOCKED" in parecer_content:
                conteudo_resposta += "\n\n‚ùå √öltimo parecer: BLOCKED"
            else:
                conteudo_resposta += "\n\n‚ö†Ô∏è √öltimo parecer: Status desconhecido"
        except Exception:
            conteudo_resposta += "\n\n‚ö†Ô∏è Erro ao ler parecer"
    else:
        conteudo_resposta += "\n\n‚ö†Ô∏è Nenhum parecer encontrado"
    
    # Verificar artefactos obrigat√≥rios
    artefactos_obrigatorios = [
        REL_DIR / "pipeline_gate_input.json",
        REL_DIR / "sbom.json",
        REL_DIR / "coverage.xml",
    ]
    
    artefactos_presentes = sum(1 for a in artefactos_obrigatorios if a.exists())
    
    conteudo_resposta += f"\n\nüì¶ Artefactos obrigat√≥rios:\n   Presentes: {artefactos_presentes}/{len(artefactos_obrigatorios)}"
    
    # Formatar resposta conforme doutrina
    resposta_formatada = formatar_resposta_agente(
        "GATEKEEPER",
        conteudo_resposta,
        pipeline_status="FORA_PIPELINE",
        proxima_acao="Status consultado",
        comando_executar="ESTADO-MAIOR VERIFICAR STATUS DO GATEKEEPER E DECIDIR PR√ìXIMA A√á√ÉO"
    )
    
    print(resposta_formatada)
    
    return 0


def cmd_limpa() -> int:
    """Executa limpeza e rota√ß√£o."""
    conteudo_resposta = "üßπ GATEKEEPER v3.0 ‚Äî Limpeza\n" + "=" * 50
    
    conteudo_resposta += "\n\n‚úÖ Limpeza conclu√≠da (sem a√ß√µes espec√≠ficas necess√°rias)"
    
    # Formatar resposta conforme doutrina
    resposta_formatada = formatar_resposta_agente(
        "GATEKEEPER",
        conteudo_resposta,
        pipeline_status="FORA_PIPELINE",
        proxima_acao="Limpeza conclu√≠da",
        comando_executar="ESTADO-MAIOR CONTINUAR OPERA√á√ÉO"
    )
    
    print(resposta_formatada)
    
    return 0


# ============================================================================
# NOVAS FUN√á√ïES DO GATEKEEPER (Conforme ordem do Estado-Maior)
# ============================================================================

def cmd_preflight() -> int:
    """
    Preflight Local (Pre-Commit): Valida workflows YAML, actions deprecadas,
    permiss√µes GITHUB_TOKEN, scripts chamados, permiss√µes de execu√ß√£o.
    """
    print("=" * 50)
    print("üõ°Ô∏è GATEKEEPER ‚Äî Preflight Local (Pre-Commit)")
    print("=" * 50)
    
    workflows_dir = REPO_ROOT / ".github" / "workflows"
    issues = []
    warnings = []
    
    if not workflows_dir.exists():
        conteudo = "‚ö†Ô∏è Nenhum workflow encontrado em .github/workflows/"
        resposta_formatada = formatar_resposta_agente(
            "GATEKEEPER",
            conteudo,
            pipeline_status="FORA_PIPELINE",
            proxima_acao="Verificar estrutura de workflows",
            comando_executar="ESTADO-MAIOR VERIFICAR ESTRUTURA DE WORKFLOWS"
        )
        print(resposta_formatada)
        return 0
    
    # Lista de actions deprecadas conhecidas (exemplos)
    deprecated_actions = [
        "actions/checkout@v1",
        "actions/checkout@v2",
        "actions/setup-python@v1",
        "actions/setup-python@v2",
        "actions/setup-python@v3",
        "actions/setup-python@v4",  # v4 ainda v√°lido, mas v5 √© preferido
    ]
    
    # Validar cada workflow
    permitted_write_permissions = {"release.yml"}

    for workflow_file in workflows_dir.glob("*.yml"):
        if not workflow_file.exists():
            continue
        
        try:
            workflow_data = load_yaml(workflow_file)
            if not isinstance(workflow_data, dict):
                warnings.append(f"{workflow_file.name}: YAML vazio ou inv√°lido")
                continue
            
            # Verificar actions deprecadas
            workflow_str = workflow_file.read_text(encoding="utf-8")
            for dep_action in deprecated_actions:
                if dep_action in workflow_str:
                    issues.append(f"{workflow_file.name}: Action deprecada detectada: {dep_action}")
            
            # Verificar permiss√µes GITHUB_TOKEN
            if "permissions" not in workflow_data or workflow_data.get("permissions") is None:
                warnings.append(f"{workflow_file.name}: Permiss√µes GITHUB_TOKEN n√£o especificadas (recomendado)")
            else:
                permissions = workflow_data.get("permissions", {})
                if (
                    permissions.get("contents") == "write"
                    and workflow_file.name not in permitted_write_permissions
                ):
                    issues.append(f"{workflow_file.name}: Permiss√£o 'contents: write' muito permissiva (risco de seguran√ßa)")
            
            # Verificar scripts chamados
            jobs = workflow_data.get("jobs", {})
            if not isinstance(jobs, dict):
                warnings.append(f"{workflow_file.name}: Estrutura jobs inv√°lida")
                continue

            for job_name, job_data in jobs.items():
                steps = job_data.get("steps", [])
                for step in steps:
                    if isinstance(step, dict):
                        run_cmd = step.get("run", "")
                        if run_cmd:
                            # Verificar se chama scripts externos sem valida√ß√£o
                            if "curl" in run_cmd and "|" in run_cmd and "bash" in run_cmd:
                                warnings.append(f"{workflow_file.name} (job {job_name}): Script externo via curl|bash (risco de seguran√ßa)")
            
        except Exception as e:
            issues.append(f"{workflow_file.name}: Erro ao validar: {e}")
    
    # Gerar relat√≥rio
    conteudo = f"""## Preflight Local ‚Äî Valida√ß√£o de Workflows

**Workflows validados:** {len(list(workflows_dir.glob("*.yml")))}

### Issues Cr√≠ticos
"""
    if issues:
        for issue in issues:
            conteudo += f"- ‚ùå {issue}\n"
    else:
        conteudo += "- ‚úÖ Nenhum issue cr√≠tico encontrado\n"
    
    conteudo += "\n### Warnings\n"
    if warnings:
        for warning in warnings:
            conteudo += f"- ‚ö†Ô∏è  {warning}\n"
    else:
        conteudo += "- ‚úÖ Nenhum warning encontrado\n"
    
    # Determinar status
    status = "PASS" if not issues else "BLOCKED"
    pipeline_status = "PIPELINE" if status == "PASS" else "FORA_PIPELINE"
    
    resposta_formatada = formatar_resposta_agente(
        "GATEKEEPER",
        conteudo,
        pipeline_status=pipeline_status,
        proxima_acao=f"Preflight conclu√≠do: {status}",
        comando_executar="ESTADO-MAIOR ANALISAR RELAT√ìRIO DE PREFLIGHT E CORRIGIR ISSUES SE NECESS√ÅRIO"
    )
    
    print(resposta_formatada)
    
    # Salvar relat√≥rio
    preflight_report = REPORTS_DIR / "preflight_report.md"
    write_text(preflight_report, resposta_formatada)
    
    return 0 if status == "PASS" else 1


def cmd_vercel_guard() -> int:
    """
    Vercel Guard (Pr√©-Deploy): Smoke local com vercel pull + vercel build (dry-run)
    + valida√ß√£o vercel.json.
    Conforme doutrina: APENAS valida√ß√£o (dry-run), nunca modifica c√≥digo.
    """
    print("=" * 50)
    print("üõ°Ô∏è GATEKEEPER ‚Äî Vercel Guard (Pr√©-Deploy)")
    print("=" * 50)
    
    vercel_json = REPO_ROOT / "vercel.json"
    issues = []
    warnings = []
    
    # Validar vercel.json se existir
    if vercel_json.exists():
        try:
            vercel_data = load_yaml(vercel_json)
            if not vercel_data:
                issues.append("vercel.json: YAML inv√°lido ou vazio")
            else:
                # Valida√ß√µes b√°sicas
                if "buildCommand" not in vercel_data and "outputDirectory" not in vercel_data:
                    warnings.append("vercel.json: buildCommand ou outputDirectory n√£o especificados")
        except Exception as e:
            issues.append(f"vercel.json: Erro ao validar: {e}")
    else:
        warnings.append("vercel.json n√£o encontrado (pode ser opcional)")
    
    # Executar vercel pull (dry-run, read-only)
    print("\nüì¶ Executando vercel pull (dry-run)...")
    vercel_token = os.environ.get("VERCEL_TOKEN")

    pull_cmd = ["vercel", "pull", "--yes", "--environment=production"]
    if vercel_token:
        pull_cmd.extend(["--token", vercel_token])

    try:
        result = subprocess.run(
            pull_cmd,
            cwd=str(REPO_ROOT),
            capture_output=True,
            text=True,
            timeout=60,
        )
        if result.returncode != 0:
            warnings.append(f"vercel pull falhou: {result.stderr[:200]}")
        elif not vercel_token:
            warnings.append("vercel pull executado sem VERCEL_TOKEN ‚Äî verifique se credenciais n√£o s√£o necess√°rias")
    except FileNotFoundError:
        warnings.append("vercel CLI n√£o encontrado (instalar: npm i -g vercel)")
    except Exception as e:
        warnings.append(f"Erro ao executar vercel pull: {e}")
    
    # Executar vercel build (dry-run, sem deploy)
    print("üî® Executando vercel build (dry-run)...")
    dry_run_confirmed = False
    dry_run_output_snippet = ""
    build_cmd = ["vercel", "build"]
    if vercel_token:
        build_cmd.extend(["--token", vercel_token])
    try:
        result = subprocess.run(
            build_cmd,
            cwd=str(REPO_ROOT),
            capture_output=True,
            text=True,
            timeout=300,
        )
        if result.returncode != 0:
            issues.append(f"vercel build (dry-run) falhou: {result.stderr[:200]}")
        else:
            combined_output = (result.stdout or "") + "\n" + (result.stderr or "")
            snippet_lines = combined_output.strip().splitlines()[:5]
            if snippet_lines:
                dry_run_output_snippet = "\n".join(snippet_lines)
            if re.search(r"build( completed)?" , combined_output, re.IGNORECASE):
                dry_run_confirmed = True
            else:
                warnings.append("vercel build executado, mas sa√≠da n√£o confirma claramente build local ‚Äî verificar CLI")
    except FileNotFoundError:
        warnings.append("vercel CLI n√£o encontrado")
    except Exception as e:
        warnings.append(f"Erro ao executar vercel build: {e}")
    
    # Gerar relat√≥rio
    conteudo = f"""## Vercel Guard ‚Äî Valida√ß√£o Pr√©-Deploy

### Valida√ß√£o vercel.json
"""
    if vercel_json.exists():
        conteudo += "- ‚úÖ vercel.json encontrado\n"
    else:
        conteudo += "- ‚ö†Ô∏è  vercel.json n√£o encontrado\n"
    
    conteudo += "\n### Issues Cr√≠ticos\n"
    if issues:
        for issue in issues:
            conteudo += f"- ‚ùå {issue}\n"
    else:
        conteudo += "- ‚úÖ Nenhum issue cr√≠tico encontrado\n"
    
    conteudo += "\n### Confirma√ß√£o do Dry-Run\n"
    if dry_run_confirmed:
        conteudo += "- ‚úÖ vercel build executado com sucesso (build local)\n"
    else:
        if any("vercel CLI n√£o encontrado" in warn for warn in warnings):
            conteudo += "- ‚ö†Ô∏è  N√£o foi poss√≠vel confirmar dry-run (CLI ausente)\n"
        elif any("vercel build (dry-run) falhou" in issue for issue in issues):
            conteudo += "- ‚ùå vercel build n√£o completou ‚Äî dry-run n√£o confirmado\n"
        elif not vercel_token:
            conteudo += "- ‚ö†Ô∏è  vercel build executado sem token ‚Äî sa√≠da parcial n√£o confirma build local\n"
        else:
            conteudo += "- ‚ö†Ô∏è  Dry-run n√£o confirmado pela sa√≠da do comando\n"
    if dry_run_output_snippet:
        conteudo += "  Sa√≠da parcial:\n  ```\n" + dry_run_output_snippet + "\n  ```\n"

    conteudo += "\n### Warnings\n"
    if warnings:
        for warning in warnings:
            conteudo += f"- ‚ö†Ô∏è  {warning}\n"
    else:
        conteudo += "- ‚úÖ Nenhum warning encontrado\n"
    
    # Determinar status
    status = "PASS" if not issues else "BLOCKED"
    pipeline_status = "PIPELINE" if status == "PASS" else "FORA_PIPELINE"
    
    resposta_formatada = formatar_resposta_agente(
        "GATEKEEPER",
        conteudo,
        pipeline_status=pipeline_status,
        proxima_acao=f"Vercel Guard conclu√≠do: {status}",
        comando_executar="ESTADO-MAIOR ANALISAR RELAT√ìRIO DE VERCEL GUARD E CORRIGIR ISSUES SE NECESS√ÅRIO"
    )
    
    print(resposta_formatada)
    
    # Salvar relat√≥rio
    vercel_report = REPORTS_DIR / "vercel_guard_report.md"
    write_text(vercel_report, resposta_formatada)
    
    return 0 if status == "PASS" else 1


def cmd_post_mortem(workflow_run_id: Optional[str] = None) -> int:
    """
    Post-Mortem (Falha): Quando workflow falhar, gera causa-raiz e patch sugerido.
    """
    print("=" * 50)
    print("üõ°Ô∏è GATEKEEPER ‚Äî Post-Mortem (An√°lise de Falha)")
    print("=" * 50)
    
    # Analisar logs de workflows falhados
    workflow_logs_dir = REPO_ROOT / ".github" / "workflows" / "logs"
    issues = []
    root_causes = []
    suggested_patches = []
    
    # Verificar se h√° logs de falha
    if workflow_logs_dir.exists():
        for log_file in workflow_logs_dir.glob("*.log"):
            try:
                log_content = log_file.read_text(encoding="utf-8")
                # An√°lise b√°sica de padr√µes de erro
                if "ERROR" in log_content or "FAILED" in log_content:
                    issues.append(f"Falha detectada em: {log_file.name}")
                    # Tentar identificar causa-raiz
                    if "SBOM" in log_content or "sbom" in log_content:
                        root_causes.append("SBOM ausente ou inv√°lido")
                        suggested_patches.append("Adicionar step de gera√ß√£o de SBOM antes da valida√ß√£o SOP")
                    if "SOP" in log_content and "BLOQUEADO" in log_content:
                        root_causes.append("Valida√ß√£o SOP bloqueada")
                        suggested_patches.append("Verificar artefactos obrigat√≥rios (coverage.xml, sbom.json, etc.)")
            except Exception:
                pass
    
    # Gerar relat√≥rio de post-mortem
    conteudo = f"""## Post-Mortem ‚Äî An√°lise de Falha

**Workflow Run ID:** {workflow_run_id or "N/A"}
**Data:** {datetime.now(timezone.utc).isoformat()}

### Issues Detectados
"""
    if issues:
        for issue in issues:
            conteudo += f"- ‚ùå {issue}\n"
    else:
        conteudo += "- ‚ö†Ô∏è  Nenhum log de falha encontrado (an√°lise baseada em padr√µes conhecidos)\n"
    
    conteudo += "\n### Causas-Raiz Identificadas\n"
    if root_causes:
        for cause in set(root_causes):  # Remover duplicados
            conteudo += f"- üîç {cause}\n"
    else:
        conteudo += "- ‚ö†Ô∏è  Nenhuma causa-raiz identificada automaticamente\n"
    
    conteudo += "\n### Patches Sugeridos\n"
    if suggested_patches:
        for patch in set(suggested_patches):  # Remover duplicados
            conteudo += f"- üîß {patch}\n"
    else:
        conteudo += "- ‚ö†Ô∏è  Nenhum patch sugerido automaticamente\n"
    
    conteudo += "\n### Recomenda√ß√µes\n"
    conteudo += "- Revisar logs completos do workflow\n"
    conteudo += "- Verificar artefactos obrigat√≥rios (SBOM, coverage, etc.)\n"
    conteudo += "- Validar conformidade com Constitui√ß√£o e Leis\n"
    
    resposta_formatada = formatar_resposta_agente(
        "GATEKEEPER",
        conteudo,
        pipeline_status="FORA_PIPELINE",
        proxima_acao="Post-mortem conclu√≠do",
        comando_executar="ESTADO-MAIOR ANALISAR POST-MORTEM E APLICAR CORRE√á√ïES SUGERIDAS"
    )
    
    print(resposta_formatada)
    
    # Salvar relat√≥rio
    postmortem_report = REPORTS_DIR / f"postmortem_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.md"
    write_text(postmortem_report, resposta_formatada)
    
    return 0


def cmd_auto_fix_alternative(issue_description: str, suggested_patch: str) -> int:
    """
    Alternativa Auto-Fix: Gatekeeper gera ordem sugerida em relat√≥rio,
    Estado-Maior ou Engenheiro pode copiar para engineer.in.yaml.
    Conforme doutrina: Gatekeeper n√£o pode modificar c√≥digo, apenas gerar relat√≥rio com ordem sugerida.
    """
    print("=" * 50)
    print("üõ°Ô∏è GATEKEEPER ‚Äî Auto-Fix Alternativo (Gerar Ordem Sugerida)")
    print("=" * 50)
    
    # Criar nova ordem com patch sugerido
    new_order = {
        "order_id": f"gk-auto-fix-{datetime.now(timezone.utc).strftime('%Y%m%d-%H%M%S')}",
        "version": 1,
        "from_role": "GATEKEEPER",
        "to_role": "ENGENHEIRO",
        "project": "F√ÅBRICA",
        "module": "CORRE√á√ÉO_AUTOM√ÅTICA",
        "gate": "FORA_PIPELINE",
        "urgency": "alta",
        "created_at": datetime.now(timezone.utc).isoformat(),
        "objective": f"Aplicar corre√ß√£o sugerida pelo Gatekeeper: {issue_description}",
        "context_refs": [
            f"relatorios/para_estado_maior/gatekeeper.out.json",
        ],
        "steps": [
            {
                "type": "command",
                "command": f"# Corre√ß√£o sugerida pelo Gatekeeper\n{suggested_patch}",
                "description": "Aplicar patch sugerido pelo Gatekeeper"
            }
        ],
        "constraints": [
            "Respeitar doutrina de acesso a ficheiros",
            "Garantir rastreabilidade (ART-04, ART-09)",
            "Validar ap√≥s aplica√ß√£o"
        ],
        "ack": {
            "by": None,
            "at": None,
            "status": "PENDING"
        },
        "status": "OPEN"
    }
    
    # Gerar relat√≥rio com ordem sugerida (Gatekeeper pode escrever relat√≥rios)
    ordem_yaml = ""
    if yaml:
        try:
            ordem_yaml = yaml.dump([new_order], allow_unicode=True, default_flow_style=False, sort_keys=False)
        except Exception:
            ordem_yaml = f"# Ordem sugerida pelo Gatekeeper\n{json.dumps(new_order, indent=2, ensure_ascii=False)}"
    
    conteudo = f"""## Auto-Fix Alternativo ‚Äî Ordem Sugerida

**Ordem ID:** {new_order['order_id']}

**Issue:** {issue_description}

**Patch Sugerido:**
```
{suggested_patch}
```

### Ordem YAML Sugerida

Para aplicar esta corre√ß√£o, copie a seguinte ordem para `ordem/ordens/engineer.in.yaml`:

```yaml
{ordem_yaml}
```

**Pr√≥ximo Passo:** Estado-Maior ou Engenheiro copiar ordem para engineer.in.yaml e Engenheiro aplicar corre√ß√£o
"""
    
    resposta_formatada = formatar_resposta_agente(
        "GATEKEEPER",
        conteudo,
        pipeline_status="FORA_PIPELINE",
        proxima_acao="Ordem sugerida gerada em relat√≥rio",
        comando_executar="ESTADO-MAIOR COPIAR ORDEM SUGERIDA PARA ordem/ordens/engineer.in.yaml E ENGENHEIRO APLICAR CORRE√á√ÉO"
    )
    
    print(resposta_formatada)
    
    # Salvar relat√≥rio (Gatekeeper pode escrever relat√≥rios)
    auto_fix_report = REPORTS_DIR / f"auto_fix_suggested_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.md"
    write_text(auto_fix_report, resposta_formatada)
    
    print(f"\n‚úÖ Relat√≥rio salvo em: {auto_fix_report.relative_to(REPO_ROOT)}")
    
    return 0


def main() -> int:
    """Fun√ß√£o principal."""
    parser = argparse.ArgumentParser(description="GATEKEEPER v3.0 ‚Äî Guardi√£o √âtico e Fiscalizador Final")
    parser.add_argument("comando", choices=["executa", "status", "limpa", "preflight", "vercel-guard", "post-mortem", "auto-fix"], help="Comando a executar")
    parser.add_argument("--workflow-run-id", help="ID do workflow run (para post-mortem)")
    parser.add_argument("--issue", help="Descri√ß√£o do issue (para auto-fix)")
    parser.add_argument("--patch", help="Patch sugerido (para auto-fix)")
    
    args = parser.parse_args()
    
    if args.comando == "executa":
        return cmd_executa()
    elif args.comando == "status":
        return cmd_status()
    elif args.comando == "limpa":
        return cmd_limpa()
    elif args.comando == "preflight":
        return cmd_preflight()
    elif args.comando == "vercel-guard":
        return cmd_vercel_guard()
    elif args.comando == "post-mortem":
        return cmd_post_mortem(args.workflow_run_id)
    elif args.comando == "auto-fix":
        if not args.issue or not args.patch:
            print("‚ùå Erro: --issue e --patch s√£o obrigat√≥rios para auto-fix")
            return 1
        return cmd_auto_fix_alternative(args.issue, args.patch)
    else:
        print(f"‚ùå Comando desconhecido: {args.comando}")
        return 1


if __name__ == "__main__":
    sys.exit(main())

